<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hadoop homework | RRRay</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="本来想要多花时间把这份作业尽量做好，结果懒癌晚期让我在deadline前两天才开始做。。。
其实现在自己连门都没入，不过近段时间恐怕都没有时间继续学习hadoop了，所以下次做实验最好能尽快回忆起已学的记下这篇流水账，。此外发现自己对linux仍然各种不熟，，，形成了这篇本质流水账
project基于hadoop 1.0.4. 属于很早的版本">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop homework">
<meta property="og:url" content="http://potatoker.github.io/2016/01/09/hadoop流水账/index.html">
<meta property="og:site_name" content="RRRay">
<meta property="og:description" content="本来想要多花时间把这份作业尽量做好，结果懒癌晚期让我在deadline前两天才开始做。。。
其实现在自己连门都没入，不过近段时间恐怕都没有时间继续学习hadoop了，所以下次做实验最好能尽快回忆起已学的记下这篇流水账，。此外发现自己对linux仍然各种不熟，，，形成了这篇本质流水账
project基于hadoop 1.0.4. 属于很早的版本">
<meta property="og:updated_time" content="2016-01-09T13:13:17.236Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop homework">
<meta name="twitter:description" content="本来想要多花时间把这份作业尽量做好，结果懒癌晚期让我在deadline前两天才开始做。。。
其实现在自己连门都没入，不过近段时间恐怕都没有时间继续学习hadoop了，所以下次做实验最好能尽快回忆起已学的记下这篇流水账，。此外发现自己对linux仍然各种不熟，，，形成了这篇本质流水账
project基于hadoop 1.0.4. 属于很早的版本">
  
    <link rel="alternative" href="/atom.xml" title="RRRay" type="application/atom+xml">
  
  
    <link rel="icon" href="/bitbug_favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
</head>
<body>
  <div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">RRRay</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/">Home</a></li><li><a href="/archives">Archives</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="/atom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://potatoker.github.io"></form>
	</div>
</header>
    <div id="main">
      <article id="post-hadoop流水账" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2016/01/09/hadoop流水账/" class="article-date">
  <time datetime="2016-01-09T12:53:30.000Z" itemprop="datePublished">2016-01-09</time>
</a>
		</span>
		<span class="meta-elements author">RRRay</span>
		<div class="commentscount">
			
				<a href="http://potatoker.github.io/2016/01/09/hadoop流水账/#disqus_thread" class="article-comment-link">Comments</a>
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 class="article-title entry-title" itemprop="name">
      Hadoop homework
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>本来想要多花时间把这份作业尽量做好，结果懒癌晚期让我在deadline前两天才开始做。。。</p>
<p>其实现在自己连门都没入，不过近段时间恐怕都没有时间继续学习hadoop了，所以下次做实验最好能尽快回忆起已学的记下这篇流水账，。<br>此外发现自己对linux仍然各种不熟，，，形成了这篇本质流水账</p>
<p>project基于hadoop 1.0.4. 属于很早的版本</p>
<a id="more"></a>
<h1 id="1-_hadoop_u5B89_u88C5"><a href="#1-_hadoop_u5B89_u88C5" class="headerlink" title="1. hadoop安装"></a>1. hadoop安装</h1><p>我装的是hadoop 1.0.4,似乎hadoop几次更新改变都很大，不过作为入门，安全起见，还是使用了老师演示版本。并且也选择了对应的Jdk6</p>
<h2 id="1-__u9884_u7F6E_u8F6F_u4EF6"><a href="#1-__u9884_u7F6E_u8F6F_u4EF6" class="headerlink" title="1. 预置软件"></a>1. 预置软件</h2><h3 id="1-jdk"><a href="#1-jdk" class="headerlink" title="1.jdk"></a>1.jdk</h3><p>sudo apt-get install openjdk-6-jdk</p>
<p>安装完之后增加到环境变量</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64   

export PATH=$PATH:$JAVA_HOME/bin 
</code></pre><p>用来检查是否生效：</p>
<pre><code>javac -version  
</code></pre><h3 id="2-_ssh"><a href="#2-_ssh" class="headerlink" title="2. ssh"></a>2. ssh</h3><pre><code>sudo apt-get install ssh
</code></pre><p>查看是否启动</p>
<pre><code>$ps -e|grep ssh
</code></pre><p><em>-e Select all processes. Identical to -A.</em><br><em>-f does full-format listing.</em></p>
<p>如果看到sshd和ssh-agent两个进程，则成功。</p>
<h2 id="2-__u5B89_u88C5hadoop"><a href="#2-__u5B89_u88C5hadoop" class="headerlink" title="2. 安装hadoop"></a>2. 安装hadoop</h2><p>1.创建用户组hadoop以及用户hadoopu：          </p>
<pre><code>sudo addgroup hadoop 

sudo adduser --ingroup hadoop hadoopu
</code></pre><p>2.将下载的hadoop.tar.gz拷入hadoopu家目录下：</p>
<pre><code>cp /downloads/hadoop-1.0.4-bin.tar.gz /home/hadoopu/
</code></pre><p>3.解压hadoop包</p>
<pre><code>tar xzf hadoop-1.0.4-bin.tar.gz
</code></pre><p>4.进入hadoop-env.sh所在目录（hadoop-1.0.4/conf/），对该文件进行如下内容的修改：</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64
</code></pre><p>（/usr/lib/jvm/java-6-openjdk-amd64为jdk安装目录）</p>
<p>5.为了方便更改环境变量，将环境变量的设置写入/etc/profile：</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64 
export HADOOP_HOME=/home/hadoopu/hadoop-1.0.4 
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin 
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/htmlconverter.jar:$JAVA_HOME/lib/jconsole.jar:$JAVA_HOME/lib/sa-jdi.jar
</code></pre><p>执行该文件，使配置生效：</p>
<pre><code>source /etc/profile
</code></pre><blockquote><p>The /etc/profile file contains system wide environment stuff and startup programs.</p>
<p>The /etc/profile file is used to set system wide environmental variables on users shells. The variables are sometimes the same ones that are in the .bash_profile, however this file is used to set an initial PATH or PS1 for all shell users of the system.</p>
</blockquote>
<p>ok. 至此安装完成了</p>
<h1 id="2-__u5728_u96C6_u7FA4_u4E0A_u8FD0_u884Cmapreduce_u7A0B_u5E8F"><a href="#2-__u5728_u96C6_u7FA4_u4E0A_u8FD0_u884Cmapreduce_u7A0B_u5E8F" class="headerlink" title="2. 在集群上运行mapreduce程序"></a>2. 在集群上运行mapreduce程序</h1><h2 id="1-__u5C06Master_u7684pubkey_u62F7_u8D1D_u5230slave_u4E0A"><a href="#1-__u5C06Master_u7684pubkey_u62F7_u8D1D_u5230slave_u4E0A" class="headerlink" title="1. 将Master的pubkey拷贝到slave上"></a>1. 将Master的pubkey拷贝到slave上</h2><p>如果没有生产过ssh-key:</p>
<pre><code>ssh-keygen -t rsa -b 4096 -C &quot;mypc&quot;
</code></pre><p>放到目标上机器，一步到位最方便的ssh-copy-id：</p>
<pre><code>ssh-copy-id username@hostname
</code></pre><h2 id="2-__u4E3Aproject_u521B_u5EFA_u6587_u4EF6_u5939_u53CAconf_u6587_u4EF6"><a href="#2-__u4E3Aproject_u521B_u5EFA_u6587_u4EF6_u5939_u53CAconf_u6587_u4EF6" class="headerlink" title="2. 为project创建文件夹及conf文件"></a>2. 为project创建文件夹及conf文件</h2><p>在/home/hadoopu下：  </p>
<pre><code>mkdir HadoopClusterTest  

cd HadoopClusterTest/ 

mkdir conf  

cp HADOOP_HOME/conf/* conf
</code></pre><p>编辑相关配置文件：  </p>
<p>core-site.xml: 用于配置Common组件的属性<br>hdfs-site.xml: 用于配置HDFS的属性<br>mapred-site.xml: 用于配置MapReduce的属性<br>masters 指定master节点 slaves 指定slave节点</p>
<p>这个project <a href="https://github.com/potatoker/hadoop-nbCliassifier/tree/master/conf" target="_blank" rel="external">conf</a>只是对老师的示例conf做了非常简单的改变.<br>这个conf包括的只是最基本的一些配置，许多属性的设置都是默认值，今后需要更好的理解hadoop才可以完善各项配置。</p>
<p>另：可以自己添加属性。</p>
<figure class="highlight pf"><figcaption><span>core-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">&lt;property&gt;</span></span><br><span class="line"><span class="variable">&lt;name&gt;</span>token_in_class_num_path<span class="variable">&lt;/name&gt;</span></span><br><span class="line"><span class="variable">&lt;value&gt;</span>hdfs://localhost/<span class="keyword">user</span>/hadoopu/classfnum/part-r-<span class="number">00000</span><span class="variable">&lt;/value&gt;</span></span><br><span class="line"><span class="variable">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure>
<p>然后在程序中，conf读入了配置文件的键值对，包括自己添加的.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Configuration conf;  </span><br><span class="line"><span class="keyword">private</span> FileSystem fs;    </span><br><span class="line">conf = context.getConfiguration();  </span><br><span class="line">fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs:///"</span>), conf);  </span><br><span class="line">Path token_in_class_num_path = <span class="keyword">new</span>  Path(conf.get(TOKEN_IN_CLASS_NUM_PATH));</span><br></pre></td></tr></table></figure></p>
<p>在project的应用是训练结果作为sequencefile放在hdfs中，分类时在程序中通过conf获取该训练结果文件所在路径，从而将文件内容读入程序.</p>
<p><strong>这里我想使用自己目录下的配置文件，需要修改环境变量:</strong></p>
<pre><code>export HADOOP_CONF_DIR=~/HadoopClusterTest/conf 
</code></pre><p>这一步十分关键，好几次自己忽略了，因而产生问题。</p>
<h2 id="3-_u542F_u52A8hadoop"><a href="#3-_u542F_u52A8hadoop" class="headerlink" title="3.启动hadoop"></a>3.启动hadoop</h2><h3 id="1-_u683C_u5F0F_u5316hdfs_3A"><a href="#1-_u683C_u5F0F_u5316hdfs_3A" class="headerlink" title="1.格式化hdfs:"></a>1.格式化hdfs:</h3><pre><code>hadoop fs namenode -format
</code></pre><h3 id="2-__u5728master_u4E0A_u542F_u52A8hadoop_u5B88_u62A4_u8FDB_u7A0B"><a href="#2-__u5728master_u4E0A_u542F_u52A8hadoop_u5B88_u62A4_u8FDB_u7A0B" class="headerlink" title="2. 在master上启动hadoop守护进程"></a>2. 在master上启动hadoop守护进程</h3><pre><code>start-all.sh
</code></pre><h3 id="3-_u4F7F_u7528jps_u67E5_u770B_u5168_u90E8hadoop_u76F8_u5173_u8FDB_u7A0B"><a href="#3-_u4F7F_u7528jps_u67E5_u770B_u5168_u90E8hadoop_u76F8_u5173_u8FDB_u7A0B" class="headerlink" title="3.使用jps查看全部hadoop相关进程"></a>3.使用jps查看全部hadoop相关进程</h3><p>在master上应该有一下三个进程:</p>
<pre><code>JobTracker
NameNode
SecondaryNameNode
</code></pre><p>在slave上应该有以下两个进程：</p>
<pre><code>TaskTracker
DataNode
</code></pre><p>并且可以看到core-site中的hadoop.tmp.dir属性指定的tmpdir被创建.</p>
<h3 id="4-_Hadoop_webUI_u8BBF_u95EE"><a href="#4-_Hadoop_webUI_u8BBF_u95EE" class="headerlink" title="4. Hadoop webUI访问"></a>4. Hadoop webUI访问</h3><ol>
<li><p>查看集群状态：<a href="http://masterIP:50070" target="_blank" rel="external">http://masterIP:50070</a></p>
</li>
<li><p>查看hdfs：<a href="http://mastetIP:50030" target="_blank" rel="external">http://mastetIP:50030</a></p>
</li>
</ol>
<p>各类log都可以通过webUI访问，集群工作时通过webUI进行监控也十分方便</p>
<h3 id="5-__u505C_u6B62hadoop_u5B88_u62A4_u8FDB_u7A0B"><a href="#5-__u505C_u6B62hadoop_u5B88_u62A4_u8FDB_u7A0B" class="headerlink" title="5. 停止hadoop守护进程"></a>5. 停止hadoop守护进程</h3><pre><code>stop-all.sh
</code></pre><p>这里遇到过一个问题是，基于上述的配置文件，当我二次格式化hdfs的时候失败，并且发现namenode启动不了了。<br>    查看log，二次格式化失败的原因似乎是因为当前hdfs在安全模式下,在安全模式下也无法删除hdfs上的文件。要解除安全模式:</p>
<pre><code>hadoop dfsadmin -safemode leave
</code></pre><p>重开：</p>
<pre><code>hadoop dfsadmin -safemode get
</code></pre><p>其实一般都不需要重新格式化hdfs…要重启的话只需stop.all.sh和start-all.sh切换即可。</p>
<h2 id="4-__u6D4B_u8BD5_u96C6_u7FA4"><a href="#4-__u6D4B_u8BD5_u96C6_u7FA4" class="headerlink" title="4. 测试集群"></a>4. 测试集群</h2><p>当然，如果做测试，可以直接使用从HADOOP_HOME中拷贝过来的conf，几乎不用做修改，只用修改slaves和master文件增加ip即可.<br>现测试运行自带的程序wordCount</p>
<h3 id="1-__u65B0_u5EFA_u6D4B_u8BD5_u6587_u672C_u6587_u4EF6test-txt_uFF0C_u6DFB_u52A0_u4EFB_u610F_u6587_u672C"><a href="#1-__u65B0_u5EFA_u6D4B_u8BD5_u6587_u672C_u6587_u4EF6test-txt_uFF0C_u6DFB_u52A0_u4EFB_u610F_u6587_u672C" class="headerlink" title="1. 新建测试文本文件test.txt，添加任意文本"></a>1. 新建测试文本文件test.txt，添加任意文本</h3><h3 id="2-__u628A_u8BE5_u6587_u4EF6_u653E_u5165hdfs_u4E2D"><a href="#2-__u628A_u8BE5_u6587_u4EF6_u653E_u5165hdfs_u4E2D" class="headerlink" title="2. 把该文件放入hdfs中"></a>2. 把该文件放入hdfs中</h3><p>在hdfs中创建目录input:</p>
<pre><code>hadoop fs -mkdir /user/hadoopu/input  
</code></pre><p>将本地文件系统的中的test.txt放入上述hdfs的input目录下：  </p>
<pre><code>hadoop fs -put /home/hadoopu/test.txt /user/hadoopu/input/
</code></pre><p>通过 -ls 参数可以查看：</p>
<pre><code>haddoop fs -ls /user/hadoopu/input
</code></pre><h3 id="3-_u8FD0_u884C_u6D4B_u8BD5_u7A0B_u5E8F"><a href="#3-_u8FD0_u884C_u6D4B_u8BD5_u7A0B_u5E8F" class="headerlink" title="3.运行测试程序"></a>3.运行测试程序</h3><p>切换到之前的HadoopCluster目录下运行:</p>
<pre><code>hadoop jar $HADOOP_HOME/hadoop-examples-1.0.4.jar wordcount /user/hadoopu/input/test/txt /user/hadoopu/output
</code></pre><p>后一个目录代表输出文件夹，如果运行前存在的话会报错。</p>
<p>wordcount表示要运行这个jar包中的主类wordcount，它应该是一个完全限定名，更多情况下形如pagege1.pakage2.wordcount</p>
<h2 id="conclusion"><a href="#conclusion" class="headerlink" title="conclusion"></a>conclusion</h2><p>其实做这个实验的时候真的暴露了很多问题，自己对真正hadoop的运行过程及原理还没有摸到皮毛，感觉这个只能算是个人note….whatever， no one else will see it.</p>
<p>马上要接下hz的活了，并行这一块的工程能力的恶补要提上日程了。</p>

    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
  <div class="article-category">
    <a class="article-category-link" href="/categories/parellel/">parellel</a>
  </div>

			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li></ul>

			</span>
		</div>
	</footer>
	
    
<nav id="article-nav">
  
  
    <a href="/2015/12/24/akka-on-android/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          akka-on-android
        
      </div>
    </a>
  
</nav>

  
</article>




<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:potatoker.github.io">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">RRRay</a>
	</h1>
	<span class="copyright">
		&copy; 2016 RRRay<br>
		Modify from <a href="http://sanographix.github.io/tumblr/apollo/" target="_blank">Apollo</a> theme, designed by <a href="http://www.sanographix.net/" target="_blank">SANOGRAPHIX.NET</a><br>
		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>
    
<script>
  var disqus_shortname = 'RRRaysblog';
  
  var disqus_url = 'http://potatoker.github.io/2016/01/09/hadoop流水账/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js" type="text/javascript"></script>
  </div>
</body>
</html>